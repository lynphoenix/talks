# 提纲
* 分享的目的是什么
* 漫谈人工智能
  * 为什么要研究人工智能
  * 什么是人工智能
  * 人工智能的层次
  * 人工智能的方向和应用领域

  * 人工智能的发展

  * 为什么是深度神经网络
    * 时代背景
      * 数据爆炸
      * 硬件升级


## 开题 - 分享的目的
同学们晚上好。
今天我分享的主题是“人工智能的发展与应用”。人工智能这个命题这两年越来越火，我觉得大家应该多少都看过听过一些介绍。那我今天呢，就随便聊聊其中的几个点吧。我打算以一个从传统机器学习过度到新时代的深度学习的研究人员的角度来谈谈这个话题，争取还是让大家有些新的收获吧。

首先来谈第一个问题，我们为什么要研究人工智能。
## 为什么是人工智能
我始终觉得我们人类生活在这个星球上是很孤独的，而且是莫名其妙的存在。所以从诞生的第一天起，人类就渴望了解这个世界。我们探索世界的方向有很多，我们仰望星空，企图知道遥远的星球上是不是有和我们一样的存在，这个世界的边界在哪里，边界的外面又是什么。我们也想了解时间的边界在哪里，它有没有起点和终点，如果说宇宙大爆炸是时间的起点的话，那这之前又是什么呢？这一切有没有终点呢？我们想知道是什么组成了我们今天的世界，各种物质的属性是什么样子，如何组成非生物和生命体。在这一切当中，也许我们首先最想要了解的是我们自己：我们身上的每个器官是如何组成我们这样的整体来运行的，我们的大脑是怎样的？自我意识来自何处？智能又是个什么东西？
人工智能就是尝试去了解我们的大脑，更确切的说，是要去了解智能是什么的一门学科。而怎样去达到这一目的呢？它的路径可以总结为Richard Feynman的这句话：What I cannot create, I do not understand.我要了解一个事物，就先去创造它。
所以人工智能呢，就是试图设计一个能在人类所处环境中表现出像人类一样智能行为的计算机来去理解智能，去了解我们的大脑。



### 什么是人工智能
好，那我们接着来聊聊，什么是人工智能。我们一直说人工智能是一个发展中的学科。那其实有一句潜台词是，我们没有非常精确的对人工智能的定义。这个问题往往会引起喋喋不休的争议。所以我们抛开正争议，来看看大人物是怎么思考这个问题的。

* 图灵测试
首先看被称为“人工智能之父”的图灵怎么看这个问题。他获得这个称号的很大的原因在于写了一篇论文《计算机器与智能》。在开篇的“Can Machine Think?”里，他提出了著名的图灵测试：如果在一个回答游戏中，机器能够骗过问问题的人，使得对方觉得回答问题的是人而不是机器，那么就认定这个机器是有智能的。
在图灵看来，人类的智能最伟大的能力在于对抽象符号的处理。所谓听和说的过程，就是我们用恰当的语法规则对被称为“词”的概念符号进行处理的过程。那视觉呢，是我们是用概念符号代表物体以及物体的位置、名称和其它属性。而处理抽象符号的能力，正是计算机能做的。在图灵看来，只要计算机能实现图灵完备的计算功能，那就能够具有智能。

* 神经元的数学模型
这个概念在我们今天看来显然是不靠谱的。但是当时的牛人们却不是这么想的。比如当时，神经科学的发展似乎为图灵的假说提供了支持。1943年，Warren McCulloch和Walter Pitts提出了神经元的数学模型。该模型认为，大脑的神经元的工作方式跟数字电路中的逻辑门是一样的。如下面图中看到的，就是一个多输入线性加权，然后通过一个激活函数输出0或1。这个基本单元跟逻辑门是一样的。这个模型现在已经被广泛接受，至少好像没有人针对这个问题提出过有说服力的质疑。
而我们知道，现在计算机的所有芯片都是这样的逻辑门构成的，不论是CPU还是内存。所以在研究人员来看，人脑和计算机的基本工作原理是一致的。这也使得有很多人觉得没有必要研究大脑，而应该把精力放在设计更好的算法和理论的研究证明上。人脑的本质是一个混沌系统，研究混沌系统呢对于设计智能机器毫无意义。计算机可以做到人脑所能做到的一切，甚至更多。

* 中文屋实验
当时自然也有很多人认为这一派的观点不靠谱。上世纪80年代就有一个著名的“中文屋”实验，对这种观点进行了一次重要的打脸活动。
这个实验是UC Berkley的著名哲学教授John Searle专门设计来打脸的。
这个实验是这样的：让一个只懂英语的人坐在一个房间里，手头有纸笔还有一本指令手册，介绍如何处理汉字。这里的处理只涉及复制、删除、插入、重排等语法指令，而并不描述任何汉字的含义。
外面的人向里面递进中文写成的问题，里头的人按手册的说明，将中文符号组合到一起写到纸上，并最后按指令将纸条递出去。
最后别人再问外面的人：这个人会不会中文。外面的人说“必须的！”
而实际上，屋里的人(相当于CPU)，不懂中文；指令手册(软件)，只是一堆正则而已，也不懂中文。实际上，这个指令手册可以认为是人试图通过编程让计算机模仿人类的行为而积累智能的结果。John Searle的意思的，无论怎么设计这个程序，计算机都不可能具有理解力，也就不可能具有智能。他说“我也不知道智能是什么，但不论智能是什么，计算机都不具备”。

以上是关于什么是人工智能这个命题的比较重要的几个思考。可以看到，观点完全无法统一。发展中的学科就是这样。就跟什么南海问题钓鱼岛问题一样。吵吵吵到最后，结论只能是“搁置争议，共同开发”。或许有一天，我们能模拟人脑的一切输入和输出，这些层面之间的相互联系可能会一目了然。但是到今天为止，这个问题很大程度上还是一个哲学问题。
那我们更重要的还是做一些实际层面的工作。比如说，给人工智能问题分分层级。

### 人工智能的三个层次
那么人工智能问题可以分为三个层次。
最底层的层次是“感知”。所谓“感”，就是将外部输入转换为大脑能够接受的信息；如果用计算机的语言来说，相当于传感器。视觉的传感器就是摄像头，听觉的传感器就是麦克风，触觉的传感器可以是压力感应器，等等。计算机能接受的传感器信号是整数或浮点数，不论是摄像头还是麦克风，最终是要通过模数信号转换形成一串无聊的数字才能被计算机所接受；而大脑也是一样，不论是视觉信号还是听觉触觉，都需要转换成生物电信号进入神经元，才能被感知。而所谓“知”，就已经是很高级的能力了。看到一个脸知道它是脸，看山是山看水是水，这个叫做“知”；听到一串声音，能辨认出它是“梦幻曲”，还是有人在喊你“吃饭”，这个是“知”；摸到一个圆圆的东西，知道它是鸡蛋，这也是“知”。但是你一定已经发现，这个“知”其实已经包含了基本的鉴别、判断、语音到文字的转换等过程。
第二个层次是“决策”。决策是在已知信息的基础上进行更高层次的判断。比如你走在街上，看到有个人向你跑来，你判断他的轨迹并不会跟你撞上；再判断他体型瘦小，速度不快，哪怕要撞上你也有足够的能力自保；此人手捧鲜花，眼神放光，你判断他是沉浸在欢愉的爱情之中，那么断不会对你造成生理上的威胁。在不到一秒钟的时间内，你已经根据“感知”层得到的各种信息，做出了三次以上的判断，并且这个判断，决定了你的行为，是避让？还是迎上？或者忽略这个人。
第三个层次是“反馈”。为什么反馈不是前两个层次中的一部分？因为反馈是构成一个有执行能力的人工智能系统的重要独立环节。它大量应用在机器人系统中。对于机器人系统来说，你可以认为反馈就是执行机构的监控系统。当无人驾驶的汽车执行刹车指令的时候，它需要反馈系统来传达刹车是否成功。另一方面，反馈也是学习的重要手段。我们大脑学习所有知识都是通过“预测 - 反馈”的路径进行的。你走进房间，看到我这个人。你脑子里会先浮现出我这个人的样子，然后再与你看到的验证。眼睛是眼睛，鼻子是鼻子，哦所以这是一个人。如果长眼睛的位置长了两个鼻子，那你一定会惊醒，然后你脑子里一些原本并不活跃的神经元开始变得活跃起来，开始学习“这个人的眼睛上居然长的是鼻子”。我们脑子进行“预测 - 反馈”的频率比你意识到的要多的多,这个过程无时不在进行。实际上我们的大脑是通过感受到的事物与预测的模式之间的匹配来学习的，这个概念可能跟传统的概念是不一样的。这个匹配的过程，靠的就是反馈。靠预测去泛化，用反馈来收敛。这是学习的原理。


### 人工智能的方向和应用领域
上面谈的是人工智能的三个层次，然后来稍微看一看研究方向和应用。
左边罗列的是最近两年的研究论文和专利申请较多的研究方向。主要是语音，自然语言处理(NLP)，视觉，机器人，浅层机器学习和深度神经网络。
需要指出的是，语音和自然语言处理是两个不同层次的事情。前者是能将声音转换为文字，而后者则是要理解文字的意思。前者现在已经可以说比较成熟了，而后者还表现的像个智障。
另外，浅层的机器学习和深度神经网络指的都是算法方面的演进。而深层和浅层，实际上指的是学习算法的层数，而不是算法本身的能力深浅。其实感觉上这是深度学习业界故意挤兑人，打嘴炮的说法。
右边罗列的是人工智能的应用领域。

* 人工智能的应用领域
  * 个人助理（智能手机上的语音助理、语音输入、家庭管家和陪护机器人） 产品举例：微软小冰、百度度秘、科大讯飞等、Amazon Echo、Google Home等
  * 安防（智能监控、安保机器人） 产品举例：商汤科技、格灵深瞳、神州云海
  * 自驾领域（智能汽车、公共交通、快递用车、工业应用） 产品举例：Google、Uber、特斯拉、亚马逊、奔驰、京东等
  * 医疗健康（医疗健康的监测诊断、智能医疗设备） 产品举例： Enlitic、Intuitive Sirgical、碳云智能、Promontory等
  * 电商零售（仓储物流、智能导购和客服） 产品举例：阿里、京东、亚马逊
  * 金融（智能投顾、智能客服、安防监控、金融监管） 产品举例：蚂蚁金服、交通银行、大华股份、kensho
  * 教育（智能评测、个性化辅导、儿童陪伴） 产品举例：学吧课堂、科大讯飞、云知声

要我说这些领域的经济价值都很大，有很多可以做而还没做好的机会。至于这些机会是否属于人工智能，我看未必。总的来说，自动驾驶、医疗、安防、金融这些领域，我觉得有比较清晰的未来，能很清晰地看到人工智能的进步带来的质变。而个人助理、教育、电商，我认为目前的机会还是在于资源和大数据的整合，本质上还是由产品经理决定的；从我的粗浅的眼光，还看不到目前的算法能力能够给这些领域带来很大的机会。如果哪天NLP进一步突破了，或许情况会有不同吧。但这需要很多顶尖算法团队的努力，而不是各小算法应用团队的努力。

### 人工智能的发展

* 达特茅斯会议

要谈人工智能的历史，怎么都得提到1956年的达特茅斯会议，这个会议被公认为是人工智能的研究起点。会议的召集者麦卡锡给这个活动起了个名字叫“人工智能夏季研讨会(Summer Research Project on Artificial Intelligence)”。这是“Artificial Intelligence”这个词第一次出现在大众的视野中。
当时参会的有六位重量级人物：
麦卡锡是会议的召集者，当时是达特茅斯学院数学系的助理教授。后来发明了AI专用的LISP语言。
明斯基，普林斯顿的数学博士，论辈分的话麦卡锡是他的师叔。他的博士论文做的就是神经网络。他设计了第一台能够自我学习的人工神经网络计算机，建立了MIT的人工智能实验室，所以他也是公认的人工智能奠基人之一。他还发明了共聚焦显微镜，发明了头戴式显示器(今天的VR的鼻祖)。他有个比他小一岁但是比他早4年博士毕业的师兄更加出名，就是“美丽心灵”电影里的主人公纳什，就是因为“博弈论”获得诺贝尔经济学奖的纳什。
塞弗里奇是模式识别的奠基人，写了第一个可工作的AI程序。他跟提出神经元数学模型的Warren McCulloch是同事，他也维纳最喜欢的学生，维纳是控制学的鼻祖。控制学是人工智能领域的重要学科。
克劳德 香农，信息论的创始人。香农这样的大神应该不用多加介绍了，他和爱因斯坦、图灵是一个级别的人物。它是信息论的创始人。大学时候的“信号与系统”就是拜他所赐开的课。他当时已经是贝尔实验室的大佬了，当时麦卡锡和明斯基都曾经在贝尔实验室当香农的小弟。相当于今天我们各路会议花大价钱请的重磅嘉(花)宾(瓶)。
纽厄尔和西蒙(Herbert Simon)：他们创立了卡内基梅隆大学(CMU)的人工智能实验室。搞计算机和控制的人都知道这是何等江湖地位。他们俩开创了人工智能的符号流派。所谓符号主义是人工智能的一个重要流派，它的核心思想是用逻辑推理的法则，从公式定义出发推演整个理论系统。但是到了今天呢，这个流派声音已经不太行了。大家都觉得这个方向有些不对劲，还是得从神经网络等方向上去寻找突破。

顺便提一句，人工智能的另外两个流派直到今天仍然非常重要：分别是行为主义和连接主义。
行为主义起源于控制论，鼻祖就是上面提到的维纳滤波的那个维纳。控制论以前主要研究的是导弹的飞行轨迹控制、化学过程控制这类复杂的多变量复杂系统的优化问题。当它把魔爪伸入人工智能领域时，主要研究的是如何模拟人和控制过程中的智能行为。人工智能领域中的机器人控制领域就是它的大本营。也就是人工智能三个层次中的“执行”部分。
也幸好行为主义的主要战场是“执行”层，所以在今天神经网络大行其道的时候还能保留一小块阵地而未沦陷。不像符号主义基本上已经溃不成军了。没错，最后一个也就是今天最重要的一个流派，就是连接主义。各位看官一定已经猜出来了，连接主义流派的领衔主演就是今天的当红炸子鸡 - 深度神经网络。

当当当，主角正式登场。

有位著名的爱唱歌的老板的歌是怎么唱的来着，“怎么大风越狠，我心越荡。。。”

你看深度神经网络今天风光无限，但是这半个多世纪可不是这样走来的。看过了世事沉浮，或许你会对深度神经网络的未来有那么一丝担忧。为什么古人要“以史为镜”，因为历史能给你提供辽阔的视角：眼看他起高楼，眼看他宴宾客，眼看他楼塌了。

简单地说，开始是上面提到的Warren McCulloch & Walter Pitts提出了神经元的数学模型。
然后一个叫Rosenblatt的年轻科学家提出了一个叫“感知器”的单层神经网络，并演示了一下这个网络能学习识别简单的图像。然后20世纪50年代的人民像今天的人民一样好骗，大家纷纷觉得神经网络好强大(AlphaGo好强大)，智能的时代来到了，人类马上要被机器取代了！于是企业界和军方都大大资助了人工智能项目，第一次高潮来到了！想想当时正是冷战开始的时候，军方对科技的狂热是我们今天难以想象的。

但是实际上从我们今天的角度看，这个感知器只能做简单的线性分类任务。于是大量人力财力投入了几年之后仍然没什么进展。终于上面提到的另一位大佬明斯基看不下去了，站出来说“你们别闹了，别不把钱当钱了”。1969年，他写了一本书叫《Preceptron》，他用数学证明了感知器连简单的异或问题都解决不了。大家无力反驳，于是纷纷转向研究其他。这是第一次人工智能也是神经网络的第一次寒潮。

到了1986年，深度学习的鼻祖Hinton出马了。他提出了两层神经网络就能解决异或问题，而且提出了反向传播算法来解决了网络的计算。然后大家惊喜地发现，一层的感知器不够牛逼但是二层的神经网络很牛逼啊，可以逼近各种函数，还可以做图像识别自动驾驶。Magnificent！于是大家又开心地进入了这一领域。各种金钱、人才都投入了这一领域。

但是很快大家发现了新的问题，网络一大，很难训练很难优化啊...直到鄙人上大学那会，介绍神经网络的定语还是“调参困难”。
恰好这时，另一位大神Vapnik提出了一种叫做支持向量机(SVM)的算法，他对神经网络深恶痛绝，自称发明SVM就是为了干死神经网络的。这种方法的自动学习能力确实要比当时的神经网络好，于是机器学习类的算法迅速成为主流。神经网络再次进入低谷。但是这次，人工智能仍然以自己的节奏前行着。

历史的车轮滚滚向前，到了2006年，深度学习的鼻祖Hinton憋了20年，憋出了一个大招 - 深度置信网络(别管置信不置信，就是神经网络)。他提出了两个方法，降低了神经网络的训练难度，一个是预训练加微调，一个是逐层优化。有了这两样利器，网络层数可以大幅增加，两层增加到两百层，不在话下！Hinton还玩了个小心思，他怕大家看到“神经网络”四个字就直接拒稿，把这种算法的名字叫做深度学习(大神当年也是小媳妇~~~)。

虽然这篇文章发在了Science上，但是仍然没有引起大家的重视。于是他老人家生气了，带着学生去搞语音，还搞了个CNN，亲力亲为参加ImageNet竞赛。2012年的时候(为什么是12年，因为06年还没有ImageNet，哈哈哈)，他们参赛的结果直接超越第二名10个百分点以上(74% vs 85%)。这下大家不淡定了。纷纷开始研究为啥你的算法这么牛逼啊。加上这个时候开源的思想伸入人心，老人家也赶新潮，把自己的程序开源了。结果人家说“你的程序里有bug”。一看真的有bug，问题是有即使bug，效果还比人家好10个点。这让人如何是好...

再后来的故事大家都知道了，仿佛是yesterday once more。大家纷纷觉得智能的时代来到了，人类马上要被机器取代了，AI科学家的年薪赶上C罗梅西了...

以上纯属八卦。为什么要聊这么久的八卦呢？想必大家也发现学术圈的八卦其实也挺多(这还是笔者做了滤波的结果，放开了聊三天三夜不在话下)。我们看学术圈的八卦就像小时候看希腊神话的感觉一样。小时候看希腊神话感觉这些神跟中国神话中的神仙们差别而太大了，中国神话中的神仙都是脸谱化的好坏分别。而希腊神话里的神，那哪叫神啊？！有偷看姑娘洗澡的，有搞大人家肚子的，有偷汉子的，还有无照驾驶开车失控撞死自己的...简直没有一个正常的。长大点了我开始觉得这叫人本主义...

我们看学术圈大神们的感觉也是一样，抛开头脑发达与否不谈，他们的生活也是鸡零狗碎，跟那些A睡了B的老婆，C嫁了D再离婚改嫁E最后跟F上床等摇滚乐队故事没什么区别。而且他们的青春时代正是摇滚乐，抽大麻，反越战，要做爱不要作战的时代。所以啊，有时决定你能走多远的，不是你生活的苟且与琐碎，而是你是否志存高远，能不能持续去追求你的兴趣所在。也许你对今天自己做的事情并不满意，但如果你以宏大的时间跨度去看，只要志存高远，思路清晰，脚踏实地，或许你就成为了某个领域的奠基人！

## 二 为什么是深度神经网络
严肃的人会问，那么神经网络为什么这么火？难道大家都是傻子吗？都不记得历史教训吗？总有很多人比冷嘲热讽的笔者智商要高吧...好的，笔者稍微正经一下谈谈今天的深度学习有什么不一样。
一如冷战时期大家对人工智能的渴望，今天深度神经网络的成功，也是有时代背景的一件事情。

那么时代背景是什么？我觉得最重要的一点是数据爆炸和硬件升级。
通讯行业和互联网经过这么多年的发展，现在已经进入数据量极大的时代。这点已无需多言。一方面是网络越来越发达，一方面是云计算的落地导致越来越多的数据堆积在云端，还有就是通讯带宽和个人终端的升级导致数据的生产量也越来越大。在做研究方面我感受最深刻的是，在学校期间做计算机视觉的样本量级还是几千到几万，能找到几万图片的数据集都两眼放光。而现在随随便便一个项目没有上百万的数据量都不好意思打招呼。
数据量级的改变带来最直接的结果是，原来打的神经网络没有还手之力的SVM和AdaBoost等工具不灵了！收敛不了了！怎么办？产业升级啊！求适应海量数据的新的算法工具呀！

我们把问题Zoom In一下。传统机器学习为什么会有这个问题呢？
笔者还在校那会做机器学习的典型流程是这样的：
样本 -> 设计特征 -> 判别算法筛选组合特征 -> 结果
本质上，特征是一种数据的映射。如果往高维数据上映射，那是为了稀疏化；如果往低维数据上映射，那是为了简化问题。然后判别算法呢，去筛选特征或者组合特征，来得到最后的算法模型。这个过程有什么问题呢？问题出在“设计”上。设计的意思就是自己想出一个特征，俗称拍脑袋。拍脑袋是什么意思？意思是没有上帝视角，没有高屋建瓴的理论指导，说的好听点叫工程直觉，说的不好听点就是靠运气。科学史又称拍脑袋史。牛顿被苹果拍了下脑袋，拍出了万有引力。门捷列夫梦到了蛇，设计出了元素周期表。如果你设计了视觉算法中的SIFT或者HOG这样成功的特征，那么恭喜你进入了名人堂。但要说这个SIFT背后是什么原理？我会告诉你在它后面上诞生的所有理论呢只是为了解释而解释。所以你要是能设计出一个好的特征，或者说找到了一个好的特征，那么你的项目了一半。
那这些特征如何能够得到判别模型呢？靠的是判别算法的学习。判别算法学的是特征的排列组合。研究学者通过一堆的数学公式证明告诉你，这些特征以某种方式去组合，能够得到一个稳健的算法模型。

那我们再看深度神经网络的典型流程，就知道为什么深度学习得以成功了。
样本 -> 神经网络 -> 结果
这区别就在于设计特征，判别算法的筛选组合被神经网络给取代了。同样是拍脑袋，那么我们自己不拍了，改让神经网络拍去。而且你会发现，之前设计特征和判别算法优化是两个相互独立的过程。特征提取不考虑算法的特性，算法迭代的时候也不会对特征提取过程给出指导性意见。而神经网络的工作方式则完全不同，特征提取蕴含在网络的每层参数之中，或者说它的特征就不是拍脑袋拍出来的，而是在模型训练的过程中学出来的。这个优点，从神经网络诞生起它就存在。像Hinton，Yann LeCun在神经网络低潮期还坚持研究20年，就是因为他们觉得神经网络这种整体优化的思路非常迷人，比“设计特征” + “判别算法”更加优雅，坚信这才是问题的出路，所以坚持了下来。之前的问题是神经网络不好收敛不好调参，但现在Hinton他们恰好解决了这个问题，于是就牛逼了。所以说到底，在数据爆炸的时代背景下，由于它解决了调参困难和海量数据下的有效训练两个问题之后，神经网络提取特征和训练模型的能力比我们自己手动设计特征要更好，这就是它成功的关键。

以上是从数据和算法的角度来谈的。那么再谈谈第二点，硬件升级。这当然是说电脑的速度越来越快了，集群规模越来越大了，云上的计算能力越来越强了。但还有一个重要玩家不得不提的就是nVidia。遥想08年的时候，笔者看到nVidia发布了一个叫CUDA的并行程序套件，能在C语言里用GPU来做大规模并行计算。于是在实验室跟博后师兄说“这玩意能改变世界”，还打印了厚厚的一本白皮书来看。
GPU与神经网络确实是天作之合。神经网络的每层都有大量的并行计算。特别是在计算机视觉领域，图像的本质就是并行的每个像素点组成的，nVidia本身也是做显卡的嘛，也正是将图像渲染中已经广泛应用的并行技术搬到了高性能计算领域。
实际上当年看到并行计算潜力的不止是nVidia，肥肉大家都看得到。同期还有个OpenCL联盟，干的事情也类似。但是ATI明显没有nVidia的决心大。nVidia花了好多年时间进行了一场豪赌，它把GPU送给各大研究所，手把手教他们用GPU来开发并行计算的程序。他们确实赌对了，深度学习在视觉和语音领域的成功，Caffe这样成功的算法库的腾空出世，让nVidia一下子站到了聚光灯下，把ATI甩的好远。估计黄仁勋的心里在某一个时刻曾感谢过ATI：“如果不是你们把我的桌面显卡的市场份额打压的那么厉害，我应该不会在cuda上押这么大的赌注，也许就不会有我的今天。”(这个故事告诉我们，你以为你尽力了，和你真的尽力了是差很远的。这世间最怕的就是人家比你出身好，比你聪明，还比你勤奋，比你思路更清晰。然后你天天在做梦超越别人...)
GPU到底给计算带来了多大的加速呢？举个例子，nVidia最新发布的P40官方号称速度是CPU的45倍(因为是多核并行计算，不是单核的处理能力)。我们现在训练的几百万样本级别的分类网络一般的训练周期是10天到一两个月。如果用CPU，那么怎么也得一年吧...
不管什么算法，如果告诉你训练一个模型需要一年，在商业上应该不太会有人为它买单...
所以本质上，深度学习今天在技术上的成功，是数据量、硬件、算法三方面合力的结果。对了，还要感谢开源算法社区和开源论文库ArXiv，大家都懂我就不提了。我也没说商业上和传播上的成功，这方面的话我觉得还要夸一夸Google和AlphaGo。要不是Google有角度而无节操的宣传，这个领域也还是一个小众的春天。体力有限，来不及感谢。


## 结语

以上就是我今天的分享。扯的比较久，非常感谢大家能抽出时间来听我吹牛。我还是希望大家听了有点点的收获。我最希望大家听完了说，原来人工智能不像媒体上吹嘘的那么神秘，没那么神奇；当然也不是说特别特别简单特别特别水，分分钟我就能做出一个来。而是说，哦原来这玩意跟我之前听到看到的不一样，居然还有这个角度。如果有人听完了说这个领域非常有意思，我要花更多的时间精力去好好了解一下这个领域。那将是我觉得最高兴看到的。
最后我想说的一句话是，AI需要想象力，需要创造力，AI也非常有意思，有广阔的天地。我希望有更多的人来加入AI的事业，一起来做更好玩，更有意思的AI。
