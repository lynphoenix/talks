# 01：计算机视觉算法导论 - 从目标识别问题开始
* 人工智能，深度学习和计算机视觉的简介
* 目标识别问题的原理和解决路径
* 用CNN构建简单的目标识别分类器
* 用TensorFlow平台解决目标分类问题

## 机器学习导论
* AI是电能
人工智能就是我们这个时代的电能，是我们这个时代的能源革命。它注定将为各个行业赋能，这是我们所有人的机会与挑战。
每一代人都有自己的使命，比如我们的祖辈的使命是革命，我们的父辈的使命是建设这个国家。而我们这代人的使命是创造新的世界，创造一个自由快乐的新世界，创造一个用智能机器彻底改造我们生活的新世界。
我觉得我们这代人很幸运，我们在经历的是一个大时代。人类历史上很少经历这样的大时代，人们的世界观、生活方式、政治秩序都在发生剧烈的动荡。今天，人工智能正在改造我们的生活的各个方面。前面20年，通讯和互联网已经将我们的生活方式颠覆了一遍，而这还只是上半场。
人工智能会接着将我们的生活重新改造一遍，很多工作岗位会被机器取代，又会有很多新的工作出现。甚至是整个世界的秩序都会被改造一遍。未来将走向何方，是需要我们每个人去思考去探索去把握的。毫无疑问的是，这是一场革命，每个人每个公司都面临选择。是拥抱革命，还是被别人革命。我们想要怎样一个未来？我们想要怎样一个世界？选择都在我们自己脚下。我希望大家一起努力，通过人工智能，去改造我们自己的行业，改造我们的生活，建设更加美好的未来。

* 人工智能、机器学习、深度学习之间的关系

人工智能就是尝试去了解我们的大脑，更确切的说，是要去了解智能是什么的一门学科。而人工智能的研究路径可以可以总结为Richard Feynman的这句话：What I cannot create, I do not understand. 我们通过创造一个事物去了解它。
所以人工智能的研究，就是希望通过设计一个真正能在人类所处环境中表现出像人类一样智能行为的计算机，来理解我们的大脑，理解智能。
机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测。与传统的为解决特定任务、硬编码的软件程序不同，机器学习是用大量的数据来“训练”，通过各种算法从数据中学习如何完成任务。
深度学习，学名其实叫做神经网络。
人工神经网络（Artificial Neural Networks）是早期机器学习中的一个重要的算法，历经数十年风风雨雨。神经网络的原理是受我们大脑的生理结构——互相交叉相连的神经元启发。但与大脑中一个神经元可以连接一定距离内的任意神经元不同，人工神经网络具有离散的层、连接和数据传播的方向。


* 人工智能的主要方向和应用领域
聊过了人工智能的三个层次后，我们可以看一眼这个领域的研究方向和应用。
左边罗列的是最近两年的研究论文和专利申请较多的研究方向。主要是语音，自然语言处理(NLP)，视觉，机器人，浅层机器学习和深度神经网络。
需要指出的是，语音和自然语言处理是两个不同层次的事情。前者是能将声音转换为文字，而后者则是要理解文字的意思。前者现在已经可以说比较成熟了，而后者还表现的像个智障。
另外，浅层的机器学习和深度神经网络指的都是算法方面的演进。而深层和浅层，实际上指的是学习算法的层数，而不是算法本身的能力深浅。其实感觉上这是深度学习业界故意挤兑人，打嘴炮的说法。
右边罗列的是人工智能的应用领域。

* 人工智能的应用领域
  * 个人助理（智能手机上的语音助理、语音输入、家庭管家和陪护机器人） 产品举例：微软小冰、百度度秘、科大讯飞等、Amazon Echo、Google Home等
  * 安防（智能监控、安保机器人） 产品举例：商汤科技、格灵深瞳、神州云海
  * 自驾领域（智能汽车、公共交通、快递用车、工业应用） 产品举例：Google、Uber、特斯拉、亚马逊、奔驰、京东等
  * 医疗健康（医疗健康的监测诊断、智能医疗设备） 产品举例： Enlitic、Intuitive Sirgical、碳云智能、Promontory等
  * 电商零售（仓储物流、智能导购和客服） 产品举例：阿里、京东、亚马逊
  * 金融（智能投顾、智能客服、安防监控、金融监管） 产品举例：蚂蚁金服、交通银行、大华股份、kensho
  * 教育（智能评测、个性化辅导、儿童陪伴） 产品举例：学吧课堂、科大讯飞、云知声

要我说这些领域的经济价值都很大，有很多可以做而还没做好的机会。至于这些机会是否属于人工智能，我看未必。总的来说，自动驾驶、医疗、安防、金融、电商这些领域，我觉得有比较清晰的未来，能很清晰地看到人工智能的进步带来的质变。而个人助理、教育，我认为目前的机会还是在于资源和大数据的整合，本质上还是由产品经理决定的；从我的粗浅的眼光，还看不到目前的算法能力能够给这些领域带来很大的机会。如果哪天NLP进一步突破了，或许情况会有不同吧。但这需要很多顶尖算法团队的努力，而不是各小算法应用团队的努力。

* 从人工智能过度到深度学习 - 为什么是深度学习
我相信在座各位也许都听说过这个问题的答案，数据爆炸和硬件升级。大家都听说过，今天大行其道的深度学习，其实上海量数据堆积出来的产品，是GPU硬件牛逼了的产品。
但你仔细想想，这里面还是有问题。为什么数据爆炸了要用今天的深度学习呢？在有深度学习之前你们做人工智能的人用的是什么方法呢？对吧。所以让我说的话，这个问题其实还有第三个要素。就是机器学习方法的革新。
上图是传统的浅层机器学习的典型流程。我在校做研究的时候就是这种方法。
样本 -> 设计特征 -> 判别算法筛选组合特征 -> 结果
本质上，特征是一种数据的映射。如果往高维数据上映射，那是为了稀疏化；如果往低维数据上映射，那是为了简化问题。然后判别算法从提取特征中提取特征或者组合特征，来得到最后的算法模型。这个过程有什么问题呢？问题出在“设计”上。设计的意思就是自己想出一个特征，俗称拍脑袋。拍脑袋是什么意思？意思是没有上帝视角，没有高屋建瓴的理论指导，说的好听点叫工程直觉，说的不好听点就是靠运气。科学史又称拍脑袋史。牛顿被苹果拍了下脑袋，拍出了万有引力。门捷列夫梦到了蛇，设计出了元素周期表。如果你设计了视觉算法中的SIFT或者HOG这样成功的特征，那么恭喜你进入了名人堂。但要说这个SIFT背后是什么原理？我会告诉你在其基础上诞生的所有理论都只是为了解释而解释。直白点的，像最简单的Haar特征一样，科学家看看猫的眼睛(因为他们没法解剖活人的眼睛啊，也有可能解剖过了，但是不敢说...)觉得是这么工作的，于是计算机视觉的研究者搬过来用，得到一个很通用的特征。
那这些简单的特征如何能够得到判别模型呢？靠的是判别算法的学习。判别算法学的是特征的排列组合。研究学者通过一堆的数学公式证明告诉你，这些特征以某种方式去组合，能够得到一个稳健的算法模型。

下图呢，是深度神经网络的流程。
样本 -> 神经网络 -> 结果
这区别就在于设计特征，判别算法的筛选组合被神经网络给取代了。同样是拍脑袋，那么我们自己不拍了，改让神经网络拍去。而且你会发现，之前设计特征和判别算法优化是两个相互独立的过程。特征提取不考虑算法的特性，算法迭代的时候也不会对特征提取过程给出指导性意见。而神经网络的工作方式则完全不同，特征提取蕴含在网络的每层参数之中，它拍脑袋的过程是由学习的目标函数直接指导的。或者说它的特征就不是拍脑袋拍出来的，而是在模型训练的过程中学出来的。这就是神经网络最大的特点，它是整体的端到端的学习方式。之前的问题是神经网络不好收敛不好调参，但到了06年的时候，Hinton提出的预训练加微调和逐层训练的学习方式，解决了这个问题。因此，它才能开始流行起来。

我最近看过一本书，书名是“人工智能的未来”。这本书对人脑的结构有一个描述：大脑皮层在外观和结构上惊人地相似，不论是主管视觉输入和主管触觉的大脑皮层区域、控制肌肉的区域、布洛卡语言区以及其他各个区域，实际上是完全一样的。大脑皮层的功能区域都遵循一个共同的算法，视觉、听觉、甚至运动输出之间没有任何差异。
神经科学家做过实验，将刚出生的雪貂的大脑经过手术重新连接，它的眼睛本来可以讲信号传输到本应是听觉发育的大脑皮层区。雪貂大脑中的听觉区形成了视觉传输路径，也就是说它们看东西时用的大脑组织本应是用来听声音的。
还有科学家用这种关系，能让盲人学会“看”。威斯康辛州立大学的生物医药工程学教授保尔*巴奇*瑞塔(Paul Bachy Rita)发明了一种在人的舌头上显示视觉模式的方法，带上他研制的装置，盲人可以通过舌上的感觉学会“看”。
他让盲人在前额戴一个小型摄像头，将视觉影像传输到舌头上的压力点上，大脑很快能学会如何正确辨别这些模式。
接受实验的人试用了这个装置后，他能看到一个球在地板上向他滚来，他伸手拿起了桌上的饮料，还能玩石头剪刀布；然后他沿着走廊往前走，看到了门，并观察了门框和门上的标牌。
这几个实验表达了什么意思呢？意思就是我们的大脑不论解决视觉、听觉、触觉，用的都是同一套机制，同一套算法。我们前面提到过，人工智能的第一个层次是感知层，也就是说人脑的感知层，对不同形式的输入，处理时用的其实是同一套算法。
是怎样的一套算法呢？看这幅图，我们的大脑解决问题用的是逐层抽象的方法。我们的大脑皮层有多个阶梯级联的，层次级的神经中枢，参见下图的V1到V5。低级区域的输出作为高级区域的输入。低级的皮层识别局部特征，越往高层，抽象程度逐渐提高。
而右边的深度神经网络，它的结构跟大脑有非常大的相似性，它也是一个逐层抽象的方式。右边的图是将各层的feature maps响应输出打印出来的结果。可以看到，最底层的神经元提取的是一些边角信息，而中间层得到的就是这些边边角角组合起来得到的眼睛鼻子等特征；到更高层的输出的就差不多是个人脸了。早上有专家也在问，卷积神经网络每层的特征怎么看，这就是可视化的方法，卷积后的feature maps可以直接可视化。

所以我们今天的人工智能，它比以往任何阶段的研究都更加接近人脑的真正工作方式。当然，这也只是比以往更加接近，而不是真正跟人脑一致，我也不敢说什么时候机器算是有智能。这个领域的发展就是这样的，年年岁岁花相似，岁岁年年人不同。
但是更加接近，而且效果非凡，仅这一点就让大家非常地兴奋了。所以我认为，这才是那些顶尖的学者、大公司都都对深度学习欢兴鼓舞，一致认为它代表了未来的重要方向的本质原因。大家在这个方向上看到了未来，至少是瞥到了一角。

## 视觉算法
* 视觉算法的内容
* 目标检测和识别方面的视觉算法的层次及其他方向

计算机视觉，作为人工智能中感知层的一个断面，它研究的是怎么模拟人眼的功能。
人眼大致有这么几个功能，一是物体的识别，二是确定物体的形状和方位，三是判断物体的运动状态。对应到计算机视觉领域，分别是目标检测和识别；地图重建，运动分析。今天的深度学习，主要是在第一个方面努力替代传统的机器学习方法。恰好我们七牛需要的视觉算法，或者说我们的客户需要的视觉算法的业务，也都集中在视觉识别的领域。后两个领域的应用场合主要是机器人。而一旦牵涉到动作执行，往往对可靠性和准确性以及性能的要求要远大于简单的辅助判断。而神经网络由于可解释性差的弱点，因此在这两个方面的进展仍然缓慢。

识别这一领域的视觉算法从简单到复杂，大致分为这几个层次：
* 最简单的是分类算法，给你一张图片，你说其中有人或者没有，色情或者不色情，这叫分类。我们七牛做的色情暴力的鉴别就是这一层次的问题。深度学习算法最先突破的ImageNet竞赛，也是分类问题。
* 比分类算法更进一步的是检测。检测问题不仅回答是不是，有没有，还要回答在哪里。比如人脸检测就是典型的问题。
* 第三个层次是语义描述。通俗地说，就是看图说话或者看视频说话。比如图中的这个例子。
这三个层次一个比一个更复杂。也就是说，一个比一个含金量高。虽然我没法很定量地说，一个检测的API应该比一个分类的API贵多少钱，而且也不是说做检测问题比做分类问题活的更好更有商业价值。但是从趋势上看，大家会越来越关注高层次的应用；而低层次的应用，由于门槛低，会越来越趋向于成为标准品。

当然，这只是个简单维度的层次划分，还有些很重要也很有意思的方向，也是我们关注的重点。比如跟踪和检测常常是打包在一起的；图像的语义分割也是很重要的方向，在视频直播等场景下有很大的商业价值，对无人驾驶来说更是至关重要。分类问题也不只有简单的“是/不是”这一个维度，比如海量商品的检索，细粒度特征的检索都是分类问题中的高精尖方向。另外，像超分辨率、风格画这些有意思的图片处理算法，也是计算机视觉领域常常受到关注的算法。


* 求解机器学习问题的一般途径
上面大致介绍了从人工智能，到机器学习，最后到深度学习这样三个概念的层层深入的递进。最后介绍了视觉算法基本从事的任务。那么我们下半场开始介绍一些实际应用层面的东西了。就是怎么用机器学习，怎么用深度神经网络去解决问题。大家可以打起精神来了。
首先要介绍一个概念是我们要解决的问题的范畴：我们要解决的问题主要分为监督学习和无监督学习两大类。
* 监督学习和无监督学习的区别
监督学习：通过已有的一部分输入数据与输出数据之间的对应关系，生成一个函数，将输入映射到合适的输出，例如分类。上面说了，计算机视觉的分类，检测等，都是有标签数据的。这些都属于监督学习。
非监督学习：直接对输入数据集进行建模，例如聚类。我们通常要学习的是数据集的整个概率分布，比如密度估计，比如合成，降噪等。还有聚类等。
然后还有半监督学习：综合利用有类标的数据和没有类标的数据，来生成合适的分类函数。
其它的还有强化学习，强化学习这种任务，算法会和环境进行交互，学习系统和训练过程会有反馈回路。这类任务我们暂时不讨论。
我们说我们今天用神经网络解决的，90%以上都是监督学习类型的任务。比如图像分类，检测这种。而且这种也是最成熟的。学习一个分布，目前被广泛应用的是像图像压缩，视频压缩，加密，降噪这类方法。

然后我们求解监督学习问题的话，通常会有三个数据集合，训练集，验证集和测试集。
训练集是用来学习模型参数的，验证集一般是用来调模型的超参数的。测试集，也就是用来评估模型在真实场景下的效能的数据集。我们会强调，这三个集合需要满足独立同分布的假设。
所谓独立同分布，在概率统计理论中，就是说变量序列或者其他随机变量有相同的概率分布，并且互相独立。
有关这类工程实践的话题，我们后面遇到问题了再展开讨论。

* 简单的神经网络的推导
**<TODO>**

z是每层的加权和输出
a是每层的神经网络输出，激活值
假设我们有一个固定样本集 \textstyle \{ (x^{(1)}, y^{(1)}), \ldots, (x^{(m)}, y^{(m)}) \}，它包含 \textstyle m 个样例。
我们可以用批量梯度下降法来求解神经网络。具体来讲，对于单个样例(x,y)，其代价函数为：
这个代价函数就是方差，或者叫二范数的表示形式。
那么这里的m个样本组成的数据集，总的代价函数就是这样的：第一项就是均方差，第二项是一个约束项，就是优化问题中的一个约束条件。这里是一个权重衰减项，目的是减少权重的幅度，防止过拟合。
因为我们的优化目标是让整体的代价函数越小越好，也就是让这个J越小越好。那么自然是两个项都要小。

我们的训练神经网络的目标是针对参数W和b使得J最小。
首先是初始化，我们会将每个参数Wij和bi初始化为一个很小的、接近零的随机值，一般会用高斯分布来初始化。
然后会对目标函数用批量梯度下降这些优化算法来优化。J是一个非凸函数，所以用梯度下降的方法优化可能会收敛到局部最优而不是全局最优。这是常态。也就是说这个学习过程不能保证一定收敛。但是一般来说得到的结果是比较靠谱的。

那么下面这个式子就是我们做一次的迭代，更新的参数。就是每一个参数都用优化函数对该参数的偏导数来更新参数。这里的alpha是学习率。这个系数决定了每次迭代的更新的步长。0-1之间
所以这里最关键的就是这个偏导数的计算。而我们就用反向传播算法，也就是BP算法来计算偏导数。

反向传播算法的思路如下：给定一个样例 (x,y)，我们首先进行“前向传导”运算，计算出网络中所有的激活值，包括 h_{W,b}(x) 的输出值。之后，针对第 l 层的每一个节点  i，我们计算出其“残差”  \delta^{(l)}_i，
残差表明了该节点对最终输出值的残差产生了多少影响。
对于最终的输出节点，我们可以直接算出网络产生的激活值与实际值之间的差距，我们将这个差距定义为 \delta^{(n_l)}_i （第 \textstyle n_l 层表示输出层）。对于隐藏单元我们如何处理呢？我们将基于节点（译者注：第 \textstyle l+1 层节点）残差的加权平均值计算 \textstyle \delta^{(l)}_i，这些节点以 \textstyle a^{(l)}_i 作为输入。下面将给出反向传导算法的细节：

进行前馈传导计算，利用前向传导公式，得到 \textstyle L_2, L_3, \ldots  直到输出层 \textstyle L_{n_l} 的激活值。
对于第 \textstyle n_l 层（输出层）的每个输出单元 \textstyle i，我们根据以下公式计算残差：
对 \textstyle l = n_l-1, n_l-2, n_l-3, \ldots, 2 的各个层，第 \textstyle l 层的第 \textstyle i 个节点的残差计算方法如下：


## 图像分类算法
分类算法的重要性 – 深度学习在视觉领域的起步
分类算法解决的问题 – 分类
分类算法的要素
分类算法是深度神经网络在计算机视觉领域最早也是最成功的应用，也是其它问题的基础。

### LeNet
先看最简单的分类算法。这是LeNet网络，Hinton的学生Yann LeCun在20世纪90年代为美国各金融机构开发的手写字符识别系统用的网络结构。由于它简单，又具备了现在的深度神经网络的大部分要素，而且效果特别好。因此被大家广泛用于解释神经网络。就像图像处理界总是拿Lena那张照片解释算法一样。话说Lena的真实身份是一个模特，这张照片其实是PlayBoy杂志里的彩页，但也不知为何就在计算机视觉领域被广泛应用了，成为这一领域广大宅男和科学家最知名的女神。她的影响力之大以至于有一次top的学术会议还请她作为嘉宾，不知道是不是跟现在的工业展会请苍老师是一回事...

### 卷积层
扯远了，接着说这个LeNet。它由几个要素组成。首先是Convolution，中文名叫卷积。在神经网络的术语中这个操作就称为“卷积层”。可以看到这个网络中有两处Convolution，代表它有两个卷积层。卷积这个名词听着不好懂，我换个名字相信有点数学知识的人都能明白，叫做“加权求和”。没错，卷积就是一个图像块每个点有不同的权重，加权求和之后作为中心点的输出值。卷积层就是用N个这样的加权模板对图像上的所有图像块求，得到一个N个新的图像。

### pooling 层
然后注意到网络里有两处Subsampling，这个叫降采样。学术名叫pooling层。其实就是缩小图像。只是这里有些不同的方法来选择缩小后图像的每个点的像素值。假设长和宽各缩短一半，那么就是在原图的2x2图像块中选择一个点：如果是4个点的像素平均一下，就叫average-pooling，如果是取4个点的最大值，就叫max-pooling。

### CNN
卷积层和pooling层交替的这么个结构，就是卷积神经网络的典型结构。它的英文名叫CNN。是不是好像在哪里听过。但凡听过一星半点的计算机视觉的介绍，比如人脸识别，应该都听到过这个名字。现在只要是跟视觉识别沾边的领域，全都是用的这种流派的算法。区别仅在于细节不同，损失函数不同。为什么？据刽子手(屠杀过很多青蛙、猴子的科学家们)说，我们的眼睛的工作方式就是这样的。就是上面说的，逐层抽象。所以你看，人工智能有时候是很没道理的，大家都是拍脑袋，无非看谁拍出来的效果好而已。到后来大家聪明了，都去找搞生物的去拜师了。

### 全连接层
第二个pooling后面有两个full connection，就是全连接层。顾名思义，把最后一个pooling输出的每个点和本层输出的每个点之间都连接上就叫全连接。原本卷积 + Pooling这个操作得到的是一个二维图片，全连接就是把最后的二维图片拉直，变成了一维的数组。只有一个全连接层还嫌不够神经网络(非线性程度不够)，还搞两个全连接层。最后再用Softmax函数做个分类输出。从前面的CNN结构，到全连接，最后到Softmax的分类输出，这就是从输入的图像(手写字符)到输出的判别结果(A-Z，0-9)的整个过程。

### 优化过程
介绍完网络架构，深度神经网络的决策过程也就清楚了。当然深度神经网络的神奇不是因为这个决策过程而是因为它的学习能力。它如何学习呢？它的学习方法叫做迭代优化，它有一个确定的、非凸的优化目标(损失函数最小化)，一点一点地向正确的方向拱。所谓损失函数，顾名思义就是衡量这个决策造成了多少损失。什么是损失呢？在分类问题里，就是原本是A，预测成了B。这就叫损失函数。计算机视觉的数学定义往往非常简单。
基本上所有机器学习问题采用的都是迭代优化的方式。深度神经网络采用的优化方法就是BP算法，正是20世纪80年代Hinton提出的优化算法。具体的理论计算过程本文就不展开了。但是要提一点，为什么同样是BP算法，20世纪80年代难以优化而现在这么成功。前面提到了Hinton在2006年用了“预训练+微调”以及"逐层优化"的方式降低了神经网络训练的难度。而到了今天大家的常规做法是用通用的分类网络(即ImageNet分类问题训练的网络)训练好的模型，针对自己应用的具体问题去调优。就是“预训练+调优”的过程。而现在的网络已经足够强大，已经不需要“逐层优化”这一方法了。

OK，这就大体讲完了分类网络的结构，推理过程，以及学习的过程。当然实际上里头的门道是很多的，有很多环节都有不同的方法去调优。但是到今天为止，主流的方法都是在这个体系之内。


## 用TensorFlow求解图像分类问题
* TensorFlow简介
TensorFlow大家应该都听过吧，就是Google开发的深度学习框架。我相信在座的应该都能理解这个框架的意思吧，就是一些工具的集合。主要有哪些工具呢？比如神经网络的各个layer的搭建，数据读取，自动求导，优化算法的代码实现等等等等。也就是说，用框架能大幅降低开发神经网络系统的时间成本。
深度学习现在主流的工具集有这么几种：TensorFlow，Caffe，MXNet，Torch等等。后面的课程，我尽量在介绍不同的算法时多用些算法框架，好让大家对主流的框架都有一点点感觉。今天就首先用现在最流行的TensorFlow来介绍分类问题的求解过程吧。

其实我个人感觉TensorFlow对我来说并不好用，论直观程度它不如Caffe，论速度效率等它不如MXNet，论改代码好用不如Torch。它的特点就是大而全。每个框架的区别、特点，是由各自的设计理念决定的，而不是说它的好与不好。比如TensorFlow它的大而全是因为Google追求的是用TensorFlow包含所有机器学习所需要的编程要素，你可以理解为他们是奔着创造一门语言的方向去的，所以它肯定要更大更重，可读性也没那么好。
所以在选择自己使用的算法框架或者你的组织做框架选型的时候一定要选择适合自己的框架，而不是一味追求最好或最流行。

* 搭建TensorFlow平台
那么我们来看怎么搭建这个平台。这个其实很简单。它有几种常用的方法，比如pip安装，docker镜像下载，源码安装。

* TensorFlow的一些重要基本概念
  * 计算图
  * 张量
  * 会话
  * 搭建简单的神经网络 - 求解cifar
  kirkn services run lessontest-lyn -i ataraxia/asetensorflow:py27-opencv2-cuda8.0-gpu --auto-restart no -n 1 --cmd="sleep infinity" --unit-type G_1U_TESLA_P4


* 本课程的代码和环境开放方式
  * 搭建TensorFlow平台
* 以AlexNet为例，介绍深度神经网络解决问题的思路和各个方面
  * 数据加载
  * 模型建立
    * 网络搭建
    * 损失函数
    * 超参数设置
  * 训练
    * 全新训练
    * fine-tune
  * 推理
* 方法的演化
最后介绍一下4种经典的CNN，分别是AlexNet，VGG，GoogLeNet，ResNet。它们分别获得了ILSRVC比赛的Classification项目的2012年冠军，2014年亚军，2014年冠军，和2015年的冠军(top-5 error 3.57%)。
注意2015年这个结果，3.57%。我这么说没有什么感觉，但我给你看另一个数字你就知道意义在哪里了。5.1%！这是受过大量训练的人在这个竞赛的数据集上能达到的成绩。也就是说，在这个领域，CNN所取得的成绩已经超过了人类！这是一个了不起的成就。所以这个图上为什么没有再放出2016的结果呢？因为2016年这个比赛已经取消了Classification这个项目了。很简单，比赛的数据集是要人来标注的。人的标注错误率已经比CNN高了。那就没法用人标定的数据来继续评价CNN的准确率了。
这个竞赛的数据集叫做ImageNet，是斯坦福的李飞飞教授在2007年创建的，收集了超过1500w张标注过的高清图片，共有22000个类别的不同物体。其中超过100w张图片是标过目标的边界框的。这个项目是在Amazon的土耳其机器人平台上众包打标的，有167的国家的近5w个人参加了这个打标和筛选的工作。
ILSVRC比赛选择了这个数据集的一个子集，选择了1000类，每个类别约1000张样本图片做训练。一共约120w的训练图片。验证集好像是5,6w图片。通常比赛衡量的是top-5和top-1的error。
下面就介绍一下这几个网络的发展演化过程。
  * AlextNet
首先是AlexNet。这个CNN应该说是一个跨时代的算法。它是神经网络在漫长的低谷期之后第一次在学界引起轰动，从此奠定CNN在计算机视觉的统治地位，也推动了深度学习在其它领域的扩展。应该算是这一轮AI热潮的起点。所以下面我们先来了解一下这个网络。
AlexNet是Hinton的学生Alex Krizhevsky设计的网络，它可以算是LeNet的升级版，设计的思路没有太大的差别。
更深更宽
应用了几个比较新的技术点
应用了ReLU、Dropout、LRN等tricks
利用了GPU+CUDA加速

输入图片是224x224
第一层的卷积核为11x11x96，步长为4；输出为55x55x96
卷积的非线性函数用的是ReLU，Rectified Linear Units。取代了神经网络中常用的sigmoid函数。用了这个非线性输出函数能大幅抑制，成功解决网络较深时的梯度弥散问题。ReLU这个函数不是AlexNet提出的，但是AlexNet发扬光大的。文章中的数据是用了ReLU能大幅提升训练的收敛速度，而且计算速度快了好多。
然后接一个LRN层，LRN(local response normalization)层的意图是对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其它反馈较小的神经元，增强模型的泛化能力。论文中提到，采用了LRN，top-5的error下降了1.2%
然后是一个3x3的max-pool层，步长为2 输出是27x27x96。用Max Pool能够避免Ave pool的模糊效果，能够更加突出主要特征。之前的神经网络普遍采用的是Ave pool，计算量大，且容易引入噪声。另外，AlexNet提出让步长比pool的kernel的尺寸小，使pool层的是输出之间有重叠和覆盖，能够提高特征的丰富性


然后是5x5x256的卷积，步长为1，后面接LRN层，输出是27x27x256
然后3x3 Max pool，步长=2，输出是13x13x256
后面是3x3x384的卷积，步长=1，输出还是13x13x384
然后再一个3x3x384的卷积，步长=1，输出还是13x13x384
再接一个3x3x256的卷积，步长=1，输出是13x13x256
最后是一个3x3 Max pool，步长=2，输出是13x13x256
然后是两个4096维的全连接层。训练过程中全连接层采用了Dropout来随机忽略一部分神经元，避免模型过拟合，随机的概率是0.5。因此预测的时候，用上了所有的神经元，但是会将输出的值全乘以0.5，用来近似对训练过程的几何平均。
最后是1000类的softmax layer输出，作分类

数据放大技术：
采用了random crop，水平flip，等方式做数据放大。提高了泛化能力
预测时，取图片的四个角加中间共5个位置，并进行左右翻转，一共获得10个图片。对10个图片进行预测，结果求均值。
对RGB图像数据进行PCA处理，并对主成分做标准差=0.1的高斯扰动，增加噪声。这个trick可以让error再下降1个点

几个有意思的特征：
前几个卷积层，计算量很大，但是餐数量很小，1M左右或更小。所以卷积层能够通过很小的参数量提取非常有效的特征。如果去掉任意一个卷积层，都会使网络分类性能大幅下降。
参数量主要集中在全连接层。参数量占90%以上


  * VGG
VGG网络是牛津大学计算机视觉组(Visual Geometry Group)  提出的。它探索了CNN的深度和性能之间的关系。通过反复堆叠3x3卷积和2x2 Max Pool，成功构建了16层和19层的CNN。
这个网络非常重要，它不是一个成熟的产品，而是一个重要的研究工作。也就是说他是在做很重要的实验，尝试的工作，去得到一些结论。而不是纯粹为了刷数据而做的工作。它仅仅证明了一些观点，而不是憋着一口气要证明自己的能力而加很多tricks。
那么它证明了什么呢？它再次证明了CNN的特点就是要Deep。而且它很优雅，结构简单：整个网络用的全是3x3的卷积和2x2的max pool，除了最后的全连接和max pool是AlexNet的常规处理。没有用任何的奇技淫巧，它是泰山北斗式的工作。我个人是非常欣赏这样的研究工作的，因为任何学科的进展都需要有这样的实验研究才能有持续的生命力。
它在ILSVRC2014的Classification取得了第二名，第一名是下面要介绍的GoogLeNet；但是在含金量更高的Localization任务上取得了第一。
因为它这个简单的结构的扩展性很强，所以被迁移到检测、分割等很多其他的视觉识别任务上。它的泛化和迁移性能非常好。所以它虽然只是一个研究性的工作，但是它的普适性比GoogleNet等用了很多工程优化的工作要好很多。
唯一美中不足指出是模型特别大。对显存的要求很高。
我们来看它的网络结构，它实验了从A到E的6种网络结构。这里的D和E就是比较常用的VGG-16和VGG-19.实际在分类问题上的效果，两者差别不大。通常是随便选择。
还要提一下，这里的C和B的差别在于多了几个1x1的卷积层，仅是多了一些线性变化，输入和输出的大小和通道数都没有变。但是看论文发现这个结构对结果很有帮助。这个结构在GoogLeNet中还会看到，它在GoogLeNet中扮演了很重要的角色。后面会再次介绍。在VGG的文章中，作者觉得这个1x1不如3x3效果好，所以在D和E中没有用它。

我们看VGG的结构，它有5段的卷积层集合。
每段里面包含了2~3个卷积层，然后相邻两段之间是有max pooling 层来缩小图片。
每段内的卷积核数量是一样的，越靠后的段的卷积核数量越多：64 - 128 - 256 - 512 -512
而且每段内有好几个完全一样的3x3卷积核堆叠。VGG是用这样的两个3x3卷积的堆叠来模拟1个5x5卷积。而3个3x3的堆叠就相当于一个7x7.但是参数个数则实际上要少很多。
2x3x3/5x5=72%
3x3x3/7x7=55%
另外，堆叠的卷积层可以使用多次的ReLU，因此对特征的学习能力比单个的5x5或7x7更强。

训练技巧：先训练A->再finetune得到B,C,D,E网络。收敛速度更快。
推理技巧：将图像scale到固定尺寸Q，然后将图片输入卷积网络计算。然后在最后一个卷积层使用滑动窗口方式进行分类的预测，将不同窗口的分类结构平均，再讲不同尺寸Q的结果平均得到最终结果。
数据放大：将原始图像缩放到不同尺寸S，再做random crop获取224x224


  * Inception
Inception就是在2014年打败了VGG获得Classification冠军的选手。它的特点是参数量和计算量都不大，但是分类性能相当好。
深度到22层，但参数量只有500w，是AlexNet的1/12
它能做到这么凶残的原因在于：
它没有全连接层。它在最后一个卷积层输出的7x7后面直接用了个avg pool取代了全连接层。前面我们提到过，全连接层占了整个AlexNet 90%多的参数量，所以这个替代巨幅减少了参数。而且！减少了过拟合！
另一个重要原因就是这个Inception结构。Inception是这个网络的精髓。它可以说是一个网络模组；可以反复堆叠形成一个大网络。
Inception模组的基本结构是个4分支的网络，第一个分支是一个1x1卷积。这里用它进行跨通道组织信息，提高网络的表达能力，对输入进行升维或降维。可以看到这里的每个分支都搭载了1x1卷积，这是因为1x1的卷积性价比很高，用很小的计算量获得特征变化和非线性化的能力。最后将各个分支的输出在通道数目上做个累加。
整个Inception结构包含了3个不同尺寸的卷积和1个max pool。这个直观的意图是要获取多尺度信息。就类似以前我们用不同尺度Haar特征、Gabor特征类似。反正计算机视觉都是靠拍脑袋的，而且都号称是借鉴人类的视觉模型。只要拍出来的效果好就皆大欢喜。
这个网络恰好拍的就很好，号称可以让网络的深度和宽度高效的扩充，提升准确率又不会过拟合。




  * ResNet
ResNet是微软的何凯明孙剑他们提出的。这几个人，还有MSRA是搞计算机视觉需要记住的几个名字。这个网络也是一个跨时代的网络。它突出的贡献是将深度学习变深了一大截。之前的AlexNet，VGG等顶多就二三十层，再深了还是会深度弥散。ResNet就是解决了这一问题，让深度学习再次变深。可以说，它重新定义了深度学习！
这个文章的思考是这样的：
首先，确定一个目标，goal是增加网络的深度。
然后开始在这个方向上做研究。然后发现，深度增加了以后，会出现Degradation。也就是准确率先上升，然后饱和，然后再增加网络深度的时候准确率会下降。这不是过拟合的问题，因为是在训练集和验证集上同时下降。
那么这个问题其实与我们的直觉是相违背的。因为你想，如果一个10层的网络已经达到了饱和的准确率，那么在后面最粗暴的方法是加几个y=x的全等映射层，起码误差不会增加。所以理论上说，网络变深，不应该带来训练集上的误差上升。
那么ResNet的灵感呢，正是出自这个y=x的恒等映射。假设某段神经网络的输入是x，期望输出是H(x)，现在他们把输入x直接传到输出作为初始结果，所以学习的目标就变成了F(x)=H(x)-x。这就是一个ResNet的残差学习单元。所以ResNet干的事情就是把学习目标改变了，从学习完整的输出H(x)变为了学习输出和输入的差别H(x)-x，也就是残差。
所以可以看到，做深度学习最重要的是思路和灵感，或者说是反复的实验。真实落实到代码层面和实现层面，只要有靠谱的框架，是非常简单也非常直观的事情。但前提是你基础扎实，思路清晰。
那么我们看这个网络的拓扑图，可以看到ResNet的最大特点在于它有很多旁路的分支，将输入直接链接到后面的层，使得后面的层可以直接学习残差。这种结构也称为shortcut或skip connection。
传统的卷积层或全连接层在传递信息的时候会存在信息丢失、损耗等问题。ResNet恰恰能够提供了一种机制来缓解这一问题。保持了信息的完整性，简化了学习目标和难度。仅需要学习输入、输出的delta部分。
ResNet这个结构非常的管用，我们下面介绍Inception的演进的时候会提到，Google用了ResNet的结构来整合到Inception结构中去后，在ImageNet上的top-5 error能降到3.08%，获得了ILSRVC2015的冠军。所以说ResNet的思想非常重要。不但是自己表现好，而且可以在各种网络结构中使用。

然后，ResNet他们team也做了演进的工作。他们在ResNet V2的论文中研究了残差学习单元的传播公式，发现前馈和反馈信号可以直接传输。因此shortcut的非线性激活函数ReLU可以替换为identity mapping，也就是直接用y=x作为激活。同时V2在每层都用了batch normalization。这样得到的新网络比之前更容易训练，泛化能力更强。


  * Inception-V4 Inception-ResNet
    * Inception v1，将1x1，3x3，5x5的conv和3x3的pooling，stack在一起，一方面增加了网络的width，另一方面增加了网络对尺度的适应性，去掉了全连接层，减少参数，加快计算速度
    * v2，一方面了加入了BN层，减少了Internal Covariate Shift（内部neuron的数据分布发生变化），使每一层的输出都规范化到一个N(0, 1)的高斯，另外一方面学习VGG用2个3x3的conv替代inception模块中的5x5，既降低了参数数量，也加速计算；
    * v3，Factorization，将7x7分解成两个一维的卷积（1x7,7x1），3x3 ->（1x3,3x1），既可以加速计算（多余的计算能力可以用来加深网络），又可以将1个conv拆成2个conv，使得网络深度进一步增加，增加了网络的非线性，可以处理更多更丰富的空间特征，增加特征多样性；更加精细设计了35x35/17x17/8x8的模块；还有值得注意的地方是网络输入从224x224变为了299x299，
  v4研究了Inception模块结合Residual Connection能不能有改进？发现ResNet的结构可以极大地加速训练，同时性能也有提升，得到一个Inception-ResNet v2网络，同时还设计了一个更深更优化的Inception v4模型，能达到与Inception-ResNet v2相媲美的性能。  

  深度神经网络求解问题的思路
   数据加载
      几种方式
    模型建立
      网络搭建
      损失函数
      训练参数设置
    启动训练

  推理
    前向计算
    信息统计

## Open questions & Homeworks
* 了解CNN各个layer的反向求导
* 了解TensorFlow的基本概念
*



python train_image_classifier.py \
 --train_dir=/disk2/data/ILSRVC2012/train/ \
 --dataset_name=imagenet \
 --dataset_split_name=train \
 --dataset_dir=/disk2/data/ILSRVC2012/record/ \
 --model_name=inception_v3 \
 --checkpoint_path=/disk2/data/ILSVRC2012/pretrained_models/tensorflow/inception_v3/inception_v3.ckpt \
 --max_number_of_steps=10000 \
 --learning_rate=0.001 \
 --learning_rate_decay_type=fixed \
 --save_interval_secs=60 \
 --save_summaries_secs=60 \
 --log_every_n_steps=100 \
 --optimizer=rmsprop \
 --weight_decay=0.00004 \
 --num_clones=2 \
 --batch_size=32 \
 2>&1 > /disk2/data/tupu/models/tensorflow/log-pulp-tf-2 &
